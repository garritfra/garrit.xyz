{"pageProps":{"post":{"slug":"_2022-05-02-docker-in-plain-english","markdownBody":"\nRecently I saw some fellow Mastodon-users discussing resources and guides to get\ninto the docker ecosystem. Given that most of my private infrastructure is built\nupon docker and docker-compose, I thought I'd share how **I** use this tool. I\nwill try to assume no prior container-knowledge, but if anything isn't clear to\nyou, feel free to [contact me](/contact).\n\n## Docker 101\n\nFirst up: What on earth is Docker, and why should I use it?\n\nDocker is a _container runtime_. It can be used to isolate system resources in a\nreproducible manner, meaning if I containerize an application on my machine, I\ncan be sure that it will function exactly the same on all machines. The benefits\nof this are obvious: You more or less eliminate all dependencies to a specific\nenvironment, like the operating system and other software. As long as it's the\nsame CPU-architecture, this sentence holds true: If it runs docker, it can run\nyour application.\n\nThings running in a container also can't break out of this \"sandbox\". A process\nin a container is only aware of the resources around it, not on the host\nmachine. Each container is kind of like an operating system **inside** your\nactual operating system.\n\nTo describe what a container should look like, we need to write a \"recipe\" for\nit. In it, you describe a starting point from which you want to build upon, and\nthe necessary steps to achieve the desired state. This \"recipe\" is called a\n`Dockerfile`. A very simple Dockerfile might look like this:\n\n```\nFROM ubuntu\n\nRUN apt update && apt upgrade -y\n\nCMD [\"echo\", \"Hello World!\"]\n```\n\nIf you now run `docker build -t hello-world .`, docker will take this recipe and\nbuild an **image** called \"hello-world\". This image is a template that describes\nthe state of your application. In our case, we take the definition provided by\nthe \"ubuntu\" image and simply do a system update. Whenever you spawn a container\nfrom this image, it will always start from exactly this state. Note that the\ncommands in the Dockerfile do not run every time you launch a container! An\nimage is the **result** of running the commands. The final instruction, `CMD`,\nis the command to run whenever you spawn a container, but more on that later.\n\nCongrats! You just built your very first docker image. To verify that it's\nactually there, try running `docker image ls`. This will list all images on your\nsystem:\n\n```\nâžœ  garrit.xyz git:(master) âœ— docker image ls\nREPOSITORY               TAG             IMAGE ID       CREATED          SIZE\nhello-world              latest          6e2240011a89   8 minutes ago    109MB\n```\n\nAn image doesn't really do anything on its own. You need to tell docker to\nconstruct a container out of that image. A container is essentially an\n**instance** of that image. Try running this command:\n\n```\ndocker run hello-world\n```\n\nAnd, as instructed with the `CMD` line, you should see the words \"Hello World!\"\nprinted on the screen. You can verify that it's still there by running `docker ps -a`, which will list all containers on your system, including the one you\njust ran:\n\n```\nCONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS                      PORTS                                            NAMES\n05415bf66a91   hello-world              \"bash\"                   3 seconds ago    Exited (0) 2 seconds ago\n```\n\n\"This isn't really helpful!\", I hear you yell. You're right, so let's look at a\nreal world example.\n\n## Example: A simple Node.js application\n\nA real world use case for a docker container is run your home-built application.\nSay we have a basic Node.js app that we wanted to containerize:\n\n```\n.\nâ”œâ”€â”€ app.js\nâ”œâ”€â”€ package-lock.json\nâ””â”€â”€ package.json\n```\n\nAnd your main setup-workflow for this application looks something like this:\n\n```\nnpm install\nnpm start\n```\n\nRemember that a Dockerfile is a **recipe** of how an application is built. A\ncorresponding recipe could look like this:\n\n```Dockerfile\n# Declare base image\nFROM node:16\n\n# Copy the application into the container\nCOPY . .\n\n# Install dependencies\nRUN npm install\n\n# Launch the application\nCMD [\"npm\", \"start\"]\n```\n\nLike above, you can build this Dockerfile using `docker build -t testapp .`, or\nany name you'd like to use.\n\n> **Quick Tip**: You might also want to add a `.Dockerignore` file, which lists\n> files and directories which should not be copied inside the container, just like\n> a `.gitignore` file. I usually add `node_modules` since it will be recreated\n> when building the image, and some files that are not relevant at runtime, like a\n> README.\n\nRunning `docker image ls` should now show the image you just created:\n\n```\nREPOSITORY               TAG             IMAGE ID       CREATED             SIZE\ntestapp                  latest          463e68d86eee   5 minutes ago       857MB\n```\n\nYou can now \"run\" the image, which will result in a spawned container. Since\nContainers run in their own environment, they won't be able to receive any\nkeystrokes by default, so you can't stop the application. To fix this, you can\nuse the `-it` flags, which will establish an interactive session to the process\ninside the container. This makes it easier to stop the container after it is\ncreated:\n\n```\ndocker run -it testapp\n```\n\nAnd voila! You should see the output of your application in the terminal. If\nyou've done some Node.js, this output might be familiar:\n\n```\nâžœ  testapp git:(master) âœ— docker run -ti testapp\n\n> testapp@1.0.0 start\n> node app.js\n\nExample app listening at http://:::8080\n```\n\nYou'll soon discover that you can't access port 8080 on your machine. Docker has\na powerful networking engine, and each container has its own IP. You _could_\nfigure out the IP of your container and access it like that. A simpler approach\nthough is to just bind a port of your host machine to the container. For\nexample, let's bind our port 4000 to port 8081 of the container. This can be\ndone using the `-p` flag of the cli:\n\n```\ndocker run -p 4000:8081 -it testapp\n```\n\n> **Quick Tip**: To remember the order of the container- and the host-port, I\n> always think of the container as laying on my desk. First, I grab the cable (the\n> host machine) and then plug it into the container. Weird analogy, I know. But it\n> really helped me make sense of this!\n\nIf you now access `http://localhost:4000` on your host machine, you should see\nyour application!\n\n## Docker Compose 101\n\nNow that we've looked at the basics of Docker, let's talk about Docker Compose.\nDocker Compose is a tool that allows you to define and manage multi-container\napplications. This means you can use a single docker-compose.yml file to define\nthe services and dependencies of your application, and then use Docker Compose\nto start and stop all of the containers at once.\n\nUsing Docker Compose can save you a lot of time and hassle, especially if you\nhave a complex application with multiple components that need to work together.\nWith Docker Compose, you can specify the dependencies between your containers,\nas well as the ports, volumes, and other settings that they need to run\nproperly. This makes it much easier to manage and maintain your application, and\nallows you to make changes to your environment quickly and easily.\n\nHere is an example docker-compose.yml file for a simple Node.js application:\n\n```yaml\nversion: '3'\nservices:\n  app:\n    build: .\n    ports:\n      - 3000:3000\n    volumes:\n      - .:/usr/src/app\n    command: npm start\n```\n\nIn this file, we define a single service called \"app\" that uses the Dockerfile\nin the current directory to build an image. We then map port 3000 on the host\nmachine to port 3000 on the container, mount the current directory as a volume,\nand specify the command to run when the container is started.\n\nTo start the containers defined in this docker-compose.yml file, you can run the following command:\n\n```\ndocker-compose up\n```\n\nThis will build the images, create the containers, and start all of the\nservices. You can then access your application at http://localhost:3000.\n\nTo stop the containers and remove them, you can run the following command:\n\n```\ndocker-compose down\n```\n\nThis will stop and remove the containers, as well as the networks and volumes\nthat we've created.\n\n## How I deploy my services\n\n- Walkthrough of a simple deployment (miniflux?)\n- Traefik\n- Local volumes\n- Permissions\n\n## Conclusion\n\n- Image size optimizations\n\nThis is post 030 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"Docker in plain english","date":"2022-05-02","tags":"guide, docker, infrastructure, 100DaysToOffload"},"tags":["guide","docker","infrastructure","100DaysToOffload"]},"recommendedPosts":[{"slug":"2023-06-01-single-page-applications-on-github-pages","markdownBody":"\nMy latest project, [sendpasswords.net](https://sendpasswords.net/) is a [Single Page Application](https://developer.mozilla.org/en-US/docs/Glossary/SPA) deployed on GitHub Pages.\n\nGitHub Pages is configured in a way to host static HTML files without any bells and whistles. This means that if you try to fetch a document that's *not* the index, for example `/foo`, the server will try to load the file with that name. \n\nBy nature, SPAs only consist of a single HTML entry point (`index.html` in most cases). It's responsible for routing the user to the correct page if there are multiple paths. And here's the crux: if the user tries to load `/foo`, he will not land at the SPA entry point. Instead, he will see a `404` error.\n\n## The solution\n\nA `404` response will automatically return a file called `404.html`, which we can use to our advantage. After building the application, simply copy the `index.html` to `404.html`, as demonstrated by [this commit](https://github.com/garritfra/sendpasswords.net/commit/66bdb68c229a3ac3386f7816a746155e658eb586). This will use `index.html` to serve the application on the root level, and `404.html` to load *the same app* if the page doesn't exist as a file. Whether the `index.html` is needed if there's already a `404.html` is up to you. I left it in to make clear that this is just a workaround.\n\nThis is a [well known](https://stackoverflow.com/a/69308662/9046809) workaround, but I wanted to bring some extra awareness to it, since it's a problem I ran into a couple of times so far. Happy SPAing!\n\n---\n\nThis is post 069 (nice) of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"Single Page Applications on GitHub Pages","date":"2023-06-01","tags":"100DaysToOffload, guide, note, web, javascript, github"},"tags":["100DaysToOffload","guide","note","web","javascript","github"]},{"slug":"2023-04-28-serverless-framework-retrospective","markdownBody":"\nA current project requires the infrastructure to be highly scalable. It's expected that > 50k Users hit the platform within a five minute period. Regular ECS containers take about one minute to scale up. That just won't cut it. I decided to go all in on the [serverless](https://www.serverless.com/) framework on AWS. Here's how it went.\r\n\r\n### Setup\r\n\r\nSetting up a serverless application was a breeze. You create a config file and use their CLI to deploy the app.\r\n\r\n### The rest of the infrastructure\r\n\r\nI decided to define the rest of the infrastructure (VPC, DB, cache, ...) in Terraform. But, since I wasn't familiar with how the Serverless Framework worked, I struggled to draw the line between what serverless should handle vs. what the rest of the infrastructure (Terraform) should provide. In a more traditional deployment workflow, you might let the CI deploy a container image to ECR and point the ECS service to that new image.\r\n\r\nI chose to let Serverless deploy the entire app through CI and build the rest of the infrastructure around it. The problem with this approach is that we lose fine-grained control over what's deployed where, which leads to a lot of permission errors.\r\n\r\nIn retrospect, I should've probably chosen the location of the S3 archive as the deployment target for the CI, and then point the lambda function to the location of the new artifact. This defeats the purpose of the framework, but it gives you a lot more control over your infrastructure. Once the next project comes along, I'll probably go that route instead.\r\n\r\n### Permissions\r\n\r\nServerless suggests to use admin permissions for deployments, and I see where they're coming from. Managing permissions in this framework is an absolute mess. Here's what the average deployment workflow looks like, if you want to use fine grained permissions:\r\n\r\n1. Wait for CloudFormation to roll back changes (~2 minutes)\r\n2. Update IAM role\r\n3. Deploy Serverless App\r\n4. If there's an error, go to 1\r\n\r\nThankfully, some people have already gone through the process of figuring this out. [Here's](https://serverlessfirst.com/create-iam-deployer-roles-serverless-app/#determining-deploy-time-permissions) a great guide with a starting point of the needed permissions.\r\n\r\n### Conclusion\r\n\r\nUsing the serverless framework is a solid choice if you just want to throw an app out there. Unfortunately the app I was deploying isn't \"just\" a dynamic website. The next time I'm building a serverless application it's probably not going to be with the Serverless Framework, though I learned a lot about serverless applications in general.\r\n\r\n---\r\n\r\nThis is post 067 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\r\n\r\n\r\n\n","frontmatter":{"title":"Serverless Framework Retrospective","date":"2023-04-28","tags":"100DaysToOffload, infrastructure, aws, note, terraform, learnings, devops, serverless"},"tags":["100DaysToOffload","infrastructure","aws","note","terraform","learnings","devops","serverless"]},{"slug":"2023-04-27-migrating-homeassistant-from-sd-to-ssd","markdownBody":"\nI finally got frustrated with the performance of my Raspberry Pi 4 running Homeassistant on a SD card, so I went ahead and got an SSD.\r\n\r\nThe migration was **very** easy:\r\n\r\n1. Create and download a full backup through the UI\r\n2. Flash Homeassistant onto the SSD\r\n3. Remove the SD card and plug the SSD into a USB 3.0 port of the Pi\r\n4. Boot\r\n5. Go through the onboarding procedure\r\n6. Restore Backup\r\n7. Profit\r\n\r\nIt worked like a charm! The speed has improved A LOT, and everything was set up as it should be. \r\n\r\n...Until we turned on the lights in the livingroom. My ZigBee-dongle, plugged into another USB port, wasn't able to communicate with the devices on the network.\r\n\r\nAfter some digging around, I came across several threads stating that an SSD over USB 3.0 apparently creates a lot of interference to surrounding hardware, including my ZigBee dongle. The fix was simple: either get an extension port for the dongle, or plug the SSD into a USB 2.0 port of the Pi. Since I didn't have an extension cord to get the dongle far away enough from the SSD, I went with the latter option for now. And that fixed it! The performance was much worse, but still better than the SD I used before. My next step will be to grab an extension cord from my parents. I'm sure they won't mind.\r\n\r\nI hope this helps!\r\n\r\n---\r\n\r\nThis is post 066 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\r\n\r\n\r\n\r\n\n","frontmatter":{"title":"Migrating Homeassistant from SD to SSD","date":"2023-04-27","tags":"100DaysToOffload, guide, note, homeassistant, homelab"},"tags":["100DaysToOffload","guide","note","homeassistant","homelab"]},{"slug":"2023-04-12-instant-dark-theme","markdownBody":"\nThanks to [Jacksons](https://jacksonchen666.com/) [update to darktheme.club](https://github.com/garritfra/darktheme.club/pull/79), I just came across a neat little [CSS property](https://developer.mozilla.org/en-US/docs/Web/CSS/color-scheme) that turns a mostly CSS-free document into a pleasantly dark site:\r\n\r\n```css\r\n:root {\r\n  color-scheme: light dark;\r\n}\r\n```\r\n\r\nThis will adjust all elements on the page to the color scheme preferred by the user - without any other custom styles! ðŸ¤¯ It is also [widely supported](https://caniuse.com/mdn-css_properties_color-scheme) by browsers.\r\n\r\nI've always been quite dependent on CSS-frameworks for any project I'm starting. Going forward, I'd be interested to see how framework-less sites would feel using this property. If all else fails, there's always the awesome [simple.css](https://simplecss.org/) library, which you can slap on top of a raw document to make it pretty (and dark, if preferred) without using custom classes.\r\n\r\n---\r\n\r\nThis is post 064 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"Instant dark theme","date":"2023-04-12","tags":"100DaysToOffload, guide, note, learnings, web, css, til"},"tags":["100DaysToOffload","guide","note","learnings","web","css","til"]},{"slug":"2023-03-30-designing-resilient-cloud-infrastructure","markdownBody":"\r\nAs mentioned in a [previous post](/posts/2023-03-16-terraform-project-learnings), I'm currently finishing up building my first cloud infrastructure on AWS for a client at work. During the development, I learned a lot about designing components to be resilient and scalable. Here are some key takeaways.\r\n\r\nOne of the most critical components of a resilient infrastructure is redundancy. On AWS, you place your components inside a \"region\". This could be `eu-central-1` (Frankfurt) or `us-east-1` (North Virgina), etc. To further reduce the risk of an outage, each region is divided into multiple [Availability Zones](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html) (AZs). The AZs of a region are usually located some distance apart from each other. In case of a flood, a fire or a bomb detonating near one AZ, the other AZs should in most cases still be intact. You should have at least two, preferably three replicas of each component across multiple availability zones in a region. By having replicas of your components in different availability zones, you reduce the risk of downtime caused by an outage in a single availability zone.\r\n\r\nAnother way to ensure scalability and resilience for your database is to use [Aurora Serverless v2](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html). This database service is specifically designed for scalable, on-demand, and cost-effective performance. The database scales itself up or down based on the workload, which allows you to automatically and dynamically adjust the database capacity to meet the demand of your application, ensuring that your application is responsive and performs well without the need for manual intervention. Adding Serverless instances to an existing RDS cluster is also a seemless proccess.\r\n\r\nIn addition to switching to Aurora Serverless v2, using read replicas for cache and database in a separate availability zone can act as a hot standby without extra configuration. Keep in mind that read replicas are only utilized by explicitly using the read-only endpoint of a cluster. But even if you're only using the \"main\" cluster endpoint (and therefore just the primary instance), a read replica can promote itself to the primary instance in case of a fail over, which drastically reduces downtime.\r\n\r\nWhen using Amazon Elastic Container Service (ECS), use Fargate as opposed to EC2 instances. Fargate is a serverless compute engine for containers that allows you to run containers without having to manage the underlying infrastructure. It smartly locates instances across availability zones, ensuring that your application is always available.\r\n\r\nIn conclusion, you should always ensure that there are more than one instance of a component in your infrastructure. There are also services on AWS that abstract away the physical infrastructure (Fargate, S3, Lambda) and use a multi-AZ pattern by default.\r\n\r\n---\r\n\r\nThis is post 061 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\r\n","frontmatter":{"title":"Designing resilient cloud infrastructure","date":"2023-03-30","tags":"100DaysToOffload, infrastructure, aws, guide, note, learnings"},"tags":["100DaysToOffload","infrastructure","aws","guide","note","learnings"]}]},"__N_SSG":true}