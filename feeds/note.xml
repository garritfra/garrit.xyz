<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>
            garrit.xyz
        </title>
        <link>
            https://garrit.xyz
        </link>
        <description>
            Garrit Franke
        </description>
        <language>
            en
        </language>
        <lastBuildDate>
            Sun, 29 Dec 2024 00:00:00 +0000
        </lastBuildDate>
        <item>
            <title>
                2024 in Review
            </title>
            <guid>
                https://garrit.xyz/posts/2024-12-29-2024-in-review
            </guid>
            <link>
                https://garrit.xyz/posts/2024-12-29-2024-in-review?utm_source=rss
            </link>
            <pubDate>
                Sun, 29 Dec 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>It&#39;s super exciting looking back at 2024. So much has happened! I haven&#39;t been very active on this blog lately, mainly because I&#39;ve been super busy in other areas of life.</p>

<p>The biggest change for me this year is one that I can cross off of my <a href="/impossible">impossible list</a>: We bought a house! I&#39;ve been wanting to write post about this for a few weeks, and now that things are settling in, I might have the time to do that. In short: We moved from Brunswick (Germany) back to a more rural town just outside Brunswick. It&#39;s closer to my girlfriends workplace, closer to my family and overall way cheaper than properties in Brunswick. We&#39;re super happy about the house and have yet to find any major annoyances. The neighbors are nice, and the community is incredibly wholesome.</p>

<p>As for other personal projects, there hasnâ€™t been as much traction as there used to be. My interests have partially shifted to hobbies that donâ€™t involve a computer, which Iâ€™m grateful for. I still love building software projects â€“ especially now that itâ€™s become so easy to get started with a project using an AI brainstorming companion â€“ I just do it less often. I picked up running as a hobby (more on that later), gather with friends to play Dungeons &amp; Dragons and work on stuff in my new basement.</p>

<h2>Goal Results</h2>

<p>These are the goals <a href="https://garrit.xyz/posts/2023-12-30-2023-in-review">I set myself for 2024</a>:</p>

<blockquote><p>Build a side project that generated at least 100â‚¬ of value</p></blockquote>

<p>Thatâ€™s a bust. As mentioned, I havenâ€™t really spent a lot of time building side projects. And the ones I did build, I consider tools rather than an income stream.</p>

<blockquote><p>Get a scuba diving license</p></blockquote>

<p>Iâ€™m a certified PADI Open Water Diver! You can see some impressions <a href="https://garrit.xyz/posts/2024-02-26-dive-log-phuket">here</a> and <a href="https://garrit.xyz/posts/2024-03-12-dive-log-vietnam">here</a>.</p>

<blockquote><p>Do a 10 km run (I really need to start moving again)</p></blockquote>

<p>I ran three 10k runs this year. <a href="https://www.strava.com/activities/11416831567">The first in May</a>, then in <a href="https://www.strava.com/activities/11768631707">June</a> and finally, <a href="https://strava.app.link/P0Ulu4L1IPb">in September</a>, I improved my 2018 personal best by a few minutes!</p>

<blockquote><p>Sell my car</p></blockquote>

<p>Check. More infos <a href="https://garrit.xyz/posts/2024-05-08-i-sold-my-car">here</a>.</p>

<blockquote><p>Write at least 50 blog posts</p></blockquote>

<p>I didnâ€™t reach this goal, but Iâ€™m also not disappointed by it. <a href="https://garrit.xyz/posts/2023-04-01-quality-vs.-quantity">The frequency of my posts varies</a>, and this year it was just lower than before.</p>

<h2>2025 Goals</h2>

<p>Here are some new goals for this year:</p>

<ul><li>Build a side project that generated at least 100â‚¬ of value (Iâ€™m keeping this goal until I reach it!)</li><li>Run a half marathon (and optionally <a href="https://www.strava.com/activities/985747064">beat my PB</a>)</li><li>Learn woodworking and build something that takes at least 3 days to complete</li></ul>

<h2>Prediction Results</h2>

<p>The results for <a href="https://garrit.xyz/posts/2023-12-30-2023-in-review">last years predictions</a>:</p>

<blockquote><p>Bitcoin will at last reach a value of 100,000$, following the<a href="https://www.nicehash.com/countdown/btc-halving-2024-05-10-12-00"> halving</a> likely happening in 2024</p></blockquote>

<p><a href="https://www.nbcnews.com/business/markets/bitcoin-100000-rcna181008">Bitcoin did reach 100,000$</a>, though not following the halving event. Still, Iâ€™d call this a pass!</p>

<blockquote><p>SpaceX will use a <a href="https://www.spacex.com/vehicles/starship/">Starship</a> prototype to launch Starlink satellites into orbit</p></blockquote>

<p>Nope, they didnâ€™t. But they made incredible leaps.</p>

<blockquote><p>Tesla cars a still not fully self driving (<a href="https://motherfrunker.ca/fsd/">reference</a>)</p></blockquote>

<p>They claim to launch it in Europe <a href="https://www.euronews.com/next/2024/09/05/tesla-says-full-self-driving-car-expected-in-europe-early-next-year-pending-regulatory-app">earlier next year</a>. Itâ€™s currently in closed testing. Still, I wouldnâ€™t give it a pass.</p>

<blockquote><p>Google will replace their main search with an AI chat bot (see<a href="https://bard.google.com/"> Bard</a>)</p></blockquote>

<p>Not sure if Iâ€™d call Gemini a full replacement, but it does have a wrapper around their traditional search engine. The product is shit compared to Anthropic and OpenAI, but I would call this a pass, since you can use Gemini instead of Google Search.</p>

<h2>2025 Predictions</h2>

<ul><li>Apple will not ship a successor to the Apple Vision Pro</li><li>At least one country will mandate AI watermarking for all AI-generated content used in commercial applications</li><li>Russia and Ukraine will come to a consensus and end the war. Ukraine will have lost territory</li></ul>

<p>And that&#39;s a wrap. I hope you all had a wonderful Christmas (if celebrated), and are as excited as I am for the new year!</p>]]>
            </description>
        </item>
        <item>
            <title>
                Installing MSSQL Client Drivers for a PHP Application
            </title>
            <guid>
                https://garrit.xyz/posts/2024-09-24-installing-mssql-client-drivers-for-a-php-application
            </guid>
            <link>
                https://garrit.xyz/posts/2024-09-24-installing-mssql-client-drivers-for-a-php-application?utm_source=rss
            </link>
            <pubDate>
                Tue, 24 Sep 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I just had the pleasure (<em>cough</em>) to connect an <a href="https://de.wikipedia.org/wiki/Microsoft_SQL_Server">MSSQL</a> database to a <a href="https://laravel.com/">Laravel</a> application at work. Because the process was <em>super</em> tedious, I wanted to quickly jot this down so I will never have to go through this again.</p>

<h2>Our setup</h2>

<p>We&#39;re building a Laravel application with <a href="https://ddev.com/">DDEV</a>. DDEV essentially moves all development tools into Docker containers and adds some nice features like local database management.</p>

<h2>The process</h2>

<p>Laravel comes with the boilerplate to use MSSQL out of the box. In your app, just set the database config to use <code>sqlsrv</code>:</p>

<p><code>php
    &#39;connections&#39; =&gt; [
        &#39;sqlsrv&#39; =&gt; [
            &#39;driver&#39; =&gt; &#39;sqlsrv&#39;,
            &#39;url&#39; =&gt; env(&#39;DB_URL&#39;),
            &#39;host&#39; =&gt; env(&#39;DB_HOST&#39;, &#39;127.0.0.1&#39;),
            &#39;port&#39; =&gt; env(&#39;DB_PORT&#39;, &#39;1433&#39;),
            &#39;database&#39; =&gt; env(&#39;DB_DATABASE&#39;, &#39;laravel&#39;),
            &#39;username&#39; =&gt; env(&#39;DB_USERNAME&#39;, &#39;root&#39;),
            &#39;password&#39; =&gt; env(&#39;DB_PASSWORD&#39;, &#39;&#39;),
            &#39;unix_socket&#39; =&gt; env(&#39;DB_SOCKET&#39;, &#39;&#39;),
            &#39;charset&#39; =&gt; env(&#39;DB_CHARSET&#39;, &#39;utf8&#39;),
            &#39;prefix&#39; =&gt; &#39;&#39;,
            &#39;prefix_indexes&#39; =&gt; true,
            // &#39;encrypt&#39; =&gt; env(&#39;DB_ENCRYPT&#39;, &#39;yes&#39;),
            // &#39;trust_server_certificate&#39; =&gt; env(&#39;DB_TRUST_SERVER_CERTIFICATE&#39;, &#39;false&#39;),
        ],
    ],
</code></p>

<p>You will see errors when starting your app, because you need to install the corresponding drivers first. Instead of adding them through <a href="https://getcomposer.org/">Composer</a> (a widely adopted package manager for PHP), you have to install the ODBC drivers <strong>through the system package manager</strong>, because Microsoft doesn&#39;t maintain a PHP package. Furthermore, you also have to install the driver repository because <strong>Microsoft doesn&#39;t even maintain packages for the major Linux distributions</strong>. In our setup with DDEV, this has to be done by amending the Dockerfile used for the application container. Create a file at <code>.ddev/web-build/Dockerfile</code> and add the following contents:</p>

<p><code></code>`dockerfile</p>

<h1>https://ddev.readthedocs.io/en/stable/users/extend/customizing-images/#adding-extra-dockerfiles-for-webimage-and-dbimage</h1>

<h1>https://stackoverflow.com/questions/58086933/how-to-install-the-sql-server-php-drivers-in-ddev-local#new-answer</h1>

<p>ARG BASE<em>IMAGE
FROM $BASE</em>IMAGE</p>

<p>RUN npm install --global forever
RUN echo &quot;Built on $(date)&quot; &gt; /build-date.txt</p>

<h1>RUN curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -</h1>

<h1>RUN curl https://packages.microsoft.com/config/debian/11/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list</h1>

<p>RUN curl -fsSL https://packages.microsoft.com/keys/microsoft.asc | sudo gpg --dearmor -o /usr/share/keyrings/microsoft-prod.gpg
RUN curl https://packages.microsoft.com/config/debian/12/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list</p>

<p>RUN apt-get update
RUN apt-get --allow-downgrades -y install libssl-dev
RUN apt-get -y update &amp;&amp; yes | ACCEPT<em>EULA=Y apt-get -y install php8.3-dev php-pear unixodbc-dev htop
RUN ACCEPT</em>EULA=Y apt-get -y install msodbcsql18 mssql-tools18
RUN sudo pecl channel-update pecl.php.net
RUN sudo pecl install sqlsrv
RUN sudo pecl install pdo_sqlsrv</p>

<p>RUN sudo printf &quot;; priority=20\nextension=sqlsrv.so\n&quot; &gt; /etc/php/8.3/mods-available/sqlsrv.ini
RUN sudo printf &quot;; priority=30\nextension=pdo<em>sqlsrv.so\n&quot; &gt; /etc/php/8.3/mods-available/pdo</em>sqlsrv.ini
RUN sudo phpenmod -v 8.3 -s cli sqlsrv pdo<em>sqlsrv
RUN sudo phpenmod -v 8.3 -s fpm sqlsrv pdo</em>sqlsrv
RUN sudo phpenmod -v 8.3 -s apache2 sqlsrv pdo_sqlsrv</p>

<p>RUN sudo printf &quot;; priority=20\nextension=sqlsrv.so\n&quot; &gt; /etc/php/8.3/mods-available/sqlsrv.ini
RUN sudo printf &quot;; priority=30\nextension=pdo<em>sqlsrv.so\n&quot; &gt; /etc/php/8.3/mods-available/pdo</em>sqlsrv.ini
RUN sudo phpenmod -v 8.3 -s cli sqlsrv pdo<em>sqlsrv
RUN sudo phpenmod -v 8.3 -s fpm sqlsrv pdo</em>sqlsrv
RUN sudo phpenmod -v 8.3 -s apache2 sqlsrv pdo_sqlsrv</p>

<p>RUN echo &#39;export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;&#39; &gt;&gt; ~/.bash_profile
<code></code>`</p>

<p>If you&#39;re reading this in the future and Microsoft may have released a new version of the ODBC drivers, you may have to follow the new <a href="https://learn.microsoft.com/de-de/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&amp;tabs=debian18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline#18">installation instructions from their documentation</a>. It took me a while to realize that I couldn&#39;t install version 17 of the driver because I was using the installation instructions for version 18. They are apparently incompatible with each other.</p>

<p>I hope that you&#39;ll never have to touch the shithole that is MSSQL, but if you do, I hope that this guide will be of value to you.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Mental AI Fog and how to cure it
            </title>
            <guid>
                https://garrit.xyz/posts/2024-09-01-AI-fog
            </guid>
            <link>
                https://garrit.xyz/posts/2024-09-01-AI-fog?utm_source=rss
            </link>
            <pubDate>
                Sun, 01 Sep 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>The term &quot;AI Slop&quot; is currently on the rise. It describes all the AI generated images and texts we see on the internet. I&#39;d like to propose a term that basically describes reverse AI Slop: <strong>Mental AI Fog</strong>.</p>

<p>Instead of <em>consuming</em> too much AI generated content (which also applies), AI Fog describes the inability to <em>produce</em> content without the help of AI. We&#39;re surrounded by flowery written articles and resources that we think that it&#39;s not worth it to put in the effort to write a text ourselves. This is comparable to how computer keyboards, spellchecking and autocorrection have rendered my generation and the ones to come incapable of comfortably writing longform text.</p>

<p>I&#39;m currently strongly suffering from AI fog. I&#39;m so used to letting some LLM flesh out a quick and dirty prompt nowadays that it&#39;s hard for me to write this text, get the point across and not feel insecure about my style of writing. This site is supposed to be a way to persist my thoughts whenever I want to, but are they still <em>my</em> thoughts if they have been proofread and corrected by a computer?</p>

<p>As a result, all these thoughts are piling up in my head. Where I previously braindumped thoughts on a piece of paper, I now only come up with a couple of words and let the AI elaborate. <strong>I&#39;m consuming what are supposed to be my own thoughts</strong>, which perpetuates the cycle.</p>

<p>This needs to stop. I need to get back <strong>creating</strong> things myself. I decided to abandon the use of LLMs for most content on this site. And where AI has been used, it will be clearly mentioned. I&#39;m contemplating adding some sort of &quot;Backed by AI&quot; label for certain pages to make it harder for myself to fall back to a helping hand. I will likely still be using LLMs, but making it obvious will force me to mindfully choose where it will be used.</p>

<p>Is this something you can relate to? Is AI fog even a fitting term for this? I don&#39;t know. And if it isn&#39;t, that&#39;s okay because I came up with it myself.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Sentiment analysis using ML models
            </title>
            <guid>
                https://garrit.xyz/posts/2024-08-31-sentiment-analysis-using-ml-models
            </guid>
            <link>
                https://garrit.xyz/posts/2024-08-31-sentiment-analysis-using-ml-models?utm_source=rss
            </link>
            <pubDate>
                Sat, 31 Aug 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I just rewrote parts of my <a href="https://github.com/garritfra/positive_hackernews">Positive Hacker News RSS Feed</a> project to use an ML model to filter out any negative news from the Hacker News timeline. This method is far more reliable than the previous method of using a <a href="https://www.nltk.org/api/nltk.sentiment.vader.html">rule-based sentiment analyzer</a> through NLTK.</p>

<p>I&#39;m using the model <a href="https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest?text=Messer-Angreiferin+verletzt+f%C3%BCnf+Menschen+in+einem+Bus">cardiffnlp/twitter-roberta-base-sentiment-latest</a>, which was trained on a huge amount of tweets. It&#39;s really tiny (~500 MB) and easily runs inside the existing GitHub Actions workflows. You can try out the model yourself on the HuggingFace model card.</p>

<p>&lt;img width=&quot;522&quot; alt=&quot;grafik&quot; src=&quot;https://github.com/user-attachments/assets/06f42df6-624a-4108-ada8-d0d37a53e693&quot;&gt;</p>

<p>If you want to subscribe to more positive tech news, simply replace your Hacker News feed of your RSS reader with this one (or add it if you haven&#39;t already):
https://garritfra.github.io/positive_hackernews/feed.xml</p>]]>
            </description>
        </item>
        <item>
            <title>
                How embedding models encode semantic meaning
            </title>
            <guid>
                https://garrit.xyz/posts/2024-08-03-how-embedding-models-encode-semantic-meaning
            </guid>
            <link>
                https://garrit.xyz/posts/2024-08-03-how-embedding-models-encode-semantic-meaning?utm_source=rss
            </link>
            <pubDate>
                Sat, 03 Aug 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Embedding models have long been a daunting concept for me. But what are they? And why are they so useful? Let&#39;s break it down in simple terms.</p>

<h2>What&#39;s an embedding?</h2>

<p>An embedding is basically a numerical representation of a piece of information - it could be text, audio, an image, or even a video. Think of it as a way to capture the essence or meaning of that information in a list of numbers.</p>

<p>For example, let&#39;s say we have this text: &quot;show me a list of ground transportation at boston airport&quot;. An embedding model might turn that into something like this:</p>

<p><code>
[0.03793335, -0.008010864, -0.002319336, -0.0110321045, -0.019882202, -0.023864746, 0.011428833, -0.030349731, -0.044830322, 0.028289795, -0.02810669, -0.0032749176, -0.04208374, -0.0077705383, -0.0033798218, -0.06335449, ... ]
</code></p>

<p>At first, thus looks like a jumble of numbers. But each of these numbers points to a specific area within the embedding model&#39;s &quot;space&quot;, where similar words or concepts might be located.</p>

<h2>Visualizing embeddings</h2>

<p>To help wrap our heads around this, let&#39;s look at a visualization. This beautiful image shows the entirety of the <a href="https://huggingface.co/nomic-ai/nomic-embed-text-v1.5">nomic-embed-text-v1.5</a> embedding model, as generated by <a href="https://atlas.nomic.ai/map/nomic-text-embed-v1-5m-sample">this visualization tool</a>:</p>

<p><img alt="nomic-embed-text-v1.5-full" src="/assets/posts/2024-08-03-how-embedding-models-encode-semantic-meaning/nomic-embed-text-v1.5-full.jpeg"/></p>

<p>Now, if we take our example text about Boston airport transportation and plot its embeddings on this map, we&#39;d see that some clusters are lit up, especially around &quot;transportation&quot;. This means that the model has figured out that the topic of the query must be related to transportation in some way.</p>

<p><img alt="nomic-embed-text-v1.5-query" src="/assets/posts/2024-08-03-how-embedding-models-encode-semantic-meaning/nomic-embed-text-v1.5-query.jpeg"/></p>

<p>Zooming into this image, we can see more specific topics around transportation, like &quot;Airport&quot;, &quot;Travel&quot; or &quot;Highways&quot; are lit up, which more closely matches our query.</p>

<p><img alt="nomic-embed-text-v1.5-transportation" src="/assets/posts/2024-08-03-how-embedding-models-encode-semantic-meaning/nomic-embed-text-v1.5-transportation.jpeg"/></p>

<p>In a nutshell, embedding models are able to group terms by topics that are related to each other.</p>

<h2>Why should we care about embeddings?</h2>

<p>Encoding meaning in text has tons of different use cases. One that I&#39;m particularly excited about is building RAG applications. RAG stands for Retrieval-Augmented Generation and refers to a method for Large Language Models (LLMs), where, given a question, you enrich the original question with relevant bits of information before answering it.</p>

<p>Here&#39;s how embeddings are useful for RAG:</p>

<ol><li>You have a bunch of documents in your data source.</li><li>You use an embedding model to turn each document into a list of numbers (like we saw earlier).</li><li>When someone asks a question, you also turn that question into a list of numbers.</li><li>Then, you find the documents whose number lists are most similar to your question&#39;s number list.</li><li>Voila! You&#39;ve found the most relevant documents to answer the question.</li></ol>

<p>This method is way better than previously used techniques like just searching for exact words in the documents. It&#39;s like the difference between having a librarian who only looks at book titles, and one who actually understands what the books are about.</p>

<h2>Other things you can do with embeddings</h2>

<p>Beyond RAG applications, embeddings are super useful for all sorts of things:</p>

<ol><li><strong>Smarter searches</strong>: Find related stuff even if the exact words don&#39;t match.</li><li><strong>Better recommendations</strong>: &quot;You liked this? You might also like these similar things!&quot;</li><li><strong>Language translation</strong>: Help computers understand that &quot;dog&quot; in English and &quot;perro&quot; in Spanish mean the same thing.</li><li><strong>Sentiment analysis</strong>: Figure out if someone&#39;s happy or grumpy based on their tweet.</li></ol>

<h2>Wrapping it up</h2>

<p>Embeddings are a clever way to turn words (or images, or sounds) into numbers that computers can understand and compare. By doing this, we can make emerging AI technologies a whole lot smarter at understanding language and finding connections between ideas.</p>

<p>Next time you&#39;re chatting with an AI or getting scarily accurate recommendations online, you can nod knowingly and think, &quot;Ah yes, embeddings at work!&quot;</p>]]>
            </description>
        </item>
        <item>
            <title>
                ðŸ”— Linkdump: LLMs
            </title>
            <guid>
                https://garrit.xyz/posts/2024-07-02-linkdump-llms
            </guid>
            <link>
                https://garrit.xyz/posts/2024-07-02-linkdump-llms?utm_source=rss
            </link>
            <pubDate>
                Tue, 02 Jul 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>The more I&#39;m getting into large language models (LLMs), the more I&#39;m fascinated about what you can do with them. To &quot;digest&quot; my reading list of cool articles and projects regarding LLMs, I assembled the following list. If you&#39;re also interested but haven&#39;t started your journey into this neverending rabbit hole, these may contain some good pointers:</p>

<h2>Running LLMs</h2>

<ul><li><a href="https://ollama.com/">Ollama</a> - Host different LLMs locally (extremely easy!)</li><li><a href="https://docs.vllm.ai">vLLM</a> - Like Ollama but more scalable and production-ready</li><li><a href="https://github.com/Mozilla-Ocho/llamafile">llamafile</a> - LLMs as a single, portable binary</li></ul>

<h2>Building Chatbots &amp; Applications</h2>

<ul><li><a href="https://www.llamaindex.ai/">LlamaIndex</a> - Framework for building LLM applications</li><li><a href="https://github.com/run-llama/create-llama/">create-llama</a> - LlamaIndex template generator (perfect for if you don&#39;t know how to structure your app)</li><li><a href="https://www.langchain.com/">LangChain</a> - Like LlamaIndex with a less clean interface IMO</li><li><a href="https://haystack.deepset.ai/overview/intro">Haystack</a> - Another LLM framework. Haven&#39;t tested it though</li><li><a href="https://sdk.vercel.ai/docs/introduction">Vercel AI SDK</a> - For integrating your LLM app into a web frontend</li></ul>

<h2>Training and finetuning</h2>

<ul><li><a href="https://huggingface.co/">HuggingFace</a> - GitHub but for LLMs</li><li><a href="https://medium.com/data-science-in-your-pocket/lora-for-fine-tuning-llms-explained-with-codes-and-example-62a7ac5a3578">LoRA for Fine-Tuning LLMs explained with codes and example</a> - Great LoRA Primer</li><li><a href="https://huggingface.co/autotrain">AutoTrain</a> - NoCode LLM finetuning</li><li><a href="https://github.com/georgian-io/LLM-Finetuning-Toolkit">llm-toolkit</a> - Another finetuning framework</li><li><a href="https://mlflow.org/">MLFlow</a> - End to End platform for LLM training</li></ul>

<h2>Miscellaneous projects</h2>

<ul><li><a href="https://github.com/iyaja/llama-fs">llama-fs</a> - Self-organinizing filesystem</li><li><a href="https://github.com/ask-fini/paramount">paramount</a> - Measure agent accuracy</li></ul>

<h2>Blogs</h2>

<ul><li><a href="https://simonwillison.net/tags/llms/">Simon Willison</a> - Awesome posts from a LLM enthusiast</li><li><a href="https://matt-rickard.com/tags/ai">Matt Richard</a> - Matt is currently inactive, but his blog is a treasure trove</li></ul>]]>
            </description>
        </item>
        <item>
            <title>
                Testing SMTP connections
            </title>
            <guid>
                https://garrit.xyz/posts/2024-06-27-testing-smtp-connections
            </guid>
            <link>
                https://garrit.xyz/posts/2024-06-27-testing-smtp-connections?utm_source=rss
            </link>
            <pubDate>
                Thu, 27 Jun 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Just a quick note to my future self on how to test a SMTP connection with nothing but a tiny busybox container.</p>

<p>In my case specifically, I tested the connection from inside a Kubernetes cluster. Here&#39;s the quickest way to get a temporary pod up and running:</p>

<p><code>
kubectl run -n backend -i --tty --rm debug --image=busybox --restart=Never
</code></p>

<p>Busybox comes with telnet installed, which we can use to establish a connection to the server:</p>

<p><code>
/ # telnet smtp.mydomain.com 25
Connected to smtp.mydomain.com
220 mail.mydomain.com ESMTP Postfix (SMTP)
</code></p>

<p>Next, we can issue the SMTP commands through the open TCP connection to send a test mail. Lines beginning with a status code are server responses:</p>

<p><code></code>`
HELO smtp.mydomain.com
250 smtp.mydomain.com
MAIL FROM:<a href="mailto:noreply@mydomain.com">noreply@mydomain.com</a>                       <br/>250 2.1.0 Ok
RCPT TO:<a href="mailto:receiver@foo.com">receiver@foo.com</a>
250 2.1.5 Ok
DATA<br/>354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;
From: [noreply] <a href="mailto:noreply@mydomain.com">noreply@mydomain.com</a>
To: [Receiver] <a href="mailto:receiver@foo.com">receiver@foo.com</a>
Date: Thu, 27 Jun 2024 10:08:26 -0200
Subject: Test Message</p>

<p>This is a test message.</p>

<p>.
250 2.0.0 Ok: queued as 2478B7F135
<code></code>`</p>

<p>In case there&#39;s a firewall issue, you might not be able to establish a connection in the first place, or you won&#39;t get a reply to your TCP commands. In our case, everything worked fine.</p>

<p>I hope this is useful!</p>]]>
            </description>
        </item>
        <item>
            <title>
                Host your own LLM
            </title>
            <guid>
                https://garrit.xyz/posts/2024-06-17-host-your-own-llm
            </guid>
            <link>
                https://garrit.xyz/posts/2024-06-17-host-your-own-llm?utm_source=rss
            </link>
            <pubDate>
                Mon, 17 Jun 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I&#39;m currently dipping my toes into Large Language Models (LLMs, or &quot;AI&quot;) and what you can do with them. It&#39;s a fascinating topic, so expect some more posts on this in the coming days and weeks.</p>

<p>For starters, I wanted to document how I got my first LLM running on my local machine (a 2022 MacBook Pro). <a href="https://ollama.com/">Ollama</a> makes this process super easy. You just install it (<code>brew install ollama</code> in my case) and then run the model:</p>

<p><code>
ollama run llama3
</code></p>

<p>This will download the model and open a prompt, so you can start chatting right away!</p>

<p>You can think of Ollama as the <a href="https://www.docker.com/">Docker</a> CLI but for LLMs. There&#39;s a <a href="https://ollama.com/library">directory of LLMs</a>, and if a model has multiple different sizes, you can use it like you would pull a different docker tag:</p>

<p><code>
ollama pull llama3:8b
ollama pull llama3:70b
</code></p>

<p>The best thing about ollama is that it also exposes a web server for you to integrate the LLM into your application. As an example, here&#39;s how you would curl your local LLM:</p>

<p><code>
curl http://localhost:11434/api/chat -d &#39;{
    &quot;model&quot;: &quot;llama3&quot;,      
    &quot;messages&quot;: [{ &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Are you a robot?&quot; }],
    &quot;stream&quot;: false
}&#39;
{&quot;model&quot;:&quot;llama3&quot;,&quot;created_at&quot;:&quot;2024-06-17T11:19:23.510588Z&quot;,&quot;message&quot;:{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I am not a human, but I&#39;m also not a traditional robot. I&#39;m an artificial intelligence language model designed to simulate conversation and answer questions to the best of my ability. My \&quot;brain\&quot; is a complex algorithm that processes natural language inputs and generates responses based on patterns and associations learned from large datasets.\n\nWhile I don&#39;t have a physical body or consciousness like humans do, I&#39;m designed to interact with humans in a way that feels natural and conversational. I can understand and respond to questions, make suggestions, and even tell jokes (though my humor may be a bit... algorithmic).\n\nSo, while I&#39;m not a human or a traditional robot, I exist at the intersection of technology and language, designed to assist and communicate with humans in a helpful way!&quot;},&quot;done_reason&quot;:&quot;stop&quot;,&quot;done&quot;:true,&quot;total_duration&quot;:12565842250,&quot;load_duration&quot;:7059262291,&quot;prompt_eval_count&quot;:15,&quot;prompt_eval_duration&quot;:331275000,&quot;eval_count&quot;:156,&quot;eval_duration&quot;:5172858000}
</code></p>

<p>If your local machine is not beefy enough and you want to try out a large LLM on a rented server (AWS has <code>g5.2xlarge</code>, which gave me good results for <code>mixtral 8x7b</code>), you also have to set <code>OLLAMA_HOST=0.0.0.0</code> in your environment variables to be able to reach the remote server. <strong>This exposes the LLM to the public internet, so be careful when chosing your deployment strategy.</strong></p>

<p>And there you go! You just deployed your very own LLM. Pretty cool, huh?</p>]]>
            </description>
        </item>
        <item>
            <title>
                I just cleaned up 40 GB of Brew caches
            </title>
            <guid>
                https://garrit.xyz/posts/2024-06-03-i-just-cleaned-up-40-gb-of-brew-caches
            </guid>
            <link>
                https://garrit.xyz/posts/2024-06-03-i-just-cleaned-up-40-gb-of-brew-caches?utm_source=rss
            </link>
            <pubDate>
                Mon, 03 Jun 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<blockquote><p><strong>EDIT</strong>: This trick will probably not be as effective on your system as it was on my system. After writing this post I realized that I had the <code>HOMEBREW_NO_INSTALL_CLEANUP=1</code> flag enabled on my system.</p></blockquote>

<p>My system (MacOS) is getting more cluttered the more I use it. I&#39;m sure you can relate. If you&#39;re using <a href="https://brew.sh/">Brew</a> as your package manager (which you should ðŸ˜‰), you might want to consider running the following command:</p>

<p><code>
brew cleanup -s
</code></p>

<p>For some reason this failed after some time with a &quot;directory not found&quot; error, but you can just run it again and it will continue cleaning up old caches. Once it was done, this freed up <strong>40 GB of disk space</strong> on my system. It might make sense to run this as a cronjob? Either way, I just wanted to jot this down before I enevitably forget this, as usual.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Going from self hosted to managed software
            </title>
            <guid>
                https://garrit.xyz/posts/2024-05-24-going-from-self-hosted-to-managed-software
            </guid>
            <link>
                https://garrit.xyz/posts/2024-05-24-going-from-self-hosted-to-managed-software?utm_source=rss
            </link>
            <pubDate>
                Fri, 24 May 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Some time ago I was heavily into <a href="https://garrit.xyz/posts/2022-09-26-self-hosted-software-im-thankful-for">self hosting my own software</a>. Over time though, it became apparent that maintaining these services is a huge burden. I either abandoned most of the services or found a replacement that suits my needs and saves me time that&#39;s better spent on other things in life.</p>

<p>Today, I finally pulled the plug on <a href="https://miniflux.app/">Miniflux</a>, the last service I used to self host (not counting House Assistant on a Pi, which I use to automate some stuff at home). The Hetzner server it ran on cost me ~4â‚¬ a month. The maintainer of Miniflux offers a managed hosting solution for 15$ a year, so to save money and time, and to support the project, I decided to switch from self-hosted to managed.</p>

<h2>Will I ever self host again?</h2>

<p>I really don&#39;t know. Some services (Miniflux included) required very little maintenance to keep running, so I could see myself spinning up a server again if I really wanted to run some software that doesn&#39;t have managed hosting. For now though, I&#39;m planning on using managed services wherever I can. Nevertheless I&#39;m proud of the things I learned during my time of self hosting my software. I think it gave me a huge boost both in terms of know how and my career, and I&#39;d encourage everyone to dip a toe into self hosting.</p>]]>
            </description>
        </item>
    </channel>
</rss>