<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>
            garrit.xyz
        </title>
        <link>
            https://garrit.xyz
        </link>
        <description>
            Garrit Franke
        </description>
        <language>
            en
        </language>
        <lastBuildDate>
            Thu, 11 Dec 2025 00:00:00 +0000
        </lastBuildDate>
        <item>
            <title>
                Custom Entities in Home Assistant
            </title>
            <guid>
                https://garrit.xyz/posts/2025-12-11-custom-entities-in-home-assistant
            </guid>
            <link>
                https://garrit.xyz/posts/2025-12-11-custom-entities-in-home-assistant?utm_source=rss
            </link>
            <pubDate>
                Thu, 11 Dec 2025 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>My local gym has a gauge on their website that shows an approximation of how many people are currently there. Being an avid <a href="https://www.home-assistant.io/">Home Assistant</a> user, of course I had to pipe that data into my dashboard somehow. For that, I created a simple <a href="https://n8n.io/">n8n</a> workflow that scrapes the data off the gym&#39;s site and dumps it into a custom entity.</p>

<p>Because creating a custom entity was not quite so straight forward as I&#39;d hoped, I wanted to share how I did it.</p>

<p>I ended up using the <code>input_number</code> integration (which seems to come with Home Assistant) and defined an entity that I could reference through the API:</p>

<p><code></code>`yaml</p>

<h1>configuration.yaml</h1>

<p>input<em>number:
  easyfitness</em>auslastung:
    name: EasyFitness Auslastung
    initial: 0
    min: 0
    max: 100
    step: 1
<code></code>`</p>

<p>After reloading the configuration, the entity was ready to be written to.</p>

<p>As mentioned, I&#39;m using a self-hosted instance of n8n on a Raspberry Pi to automate this. Using their <a href="https://n8n.io/integrations/home-assistant/">Home Assistant Integration</a>, you can simply address the new entity and update its state. And just like that, I was able to add a new Gauge to my dashboard!</p>]]>
            </description>
        </item>
        <item>
            <title>
                Host your own LLM
            </title>
            <guid>
                https://garrit.xyz/posts/2024-06-17-host-your-own-llm
            </guid>
            <link>
                https://garrit.xyz/posts/2024-06-17-host-your-own-llm?utm_source=rss
            </link>
            <pubDate>
                Mon, 17 Jun 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I&#39;m currently dipping my toes into Large Language Models (LLMs, or &quot;AI&quot;) and what you can do with them. It&#39;s a fascinating topic, so expect some more posts on this in the coming days and weeks.</p>

<p>For starters, I wanted to document how I got my first LLM running on my local machine (a 2022 MacBook Pro). <a href="https://ollama.com/">Ollama</a> makes this process super easy. You just install it (<code>brew install ollama</code> in my case) and then run the model:</p>

<p><code>
ollama run llama3
</code></p>

<p>This will download the model and open a prompt, so you can start chatting right away!</p>

<p>You can think of Ollama as the <a href="https://www.docker.com/">Docker</a> CLI but for LLMs. There&#39;s a <a href="https://ollama.com/library">directory of LLMs</a>, and if a model has multiple different sizes, you can use it like you would pull a different docker tag:</p>

<p><code>
ollama pull llama3:8b
ollama pull llama3:70b
</code></p>

<p>The best thing about ollama is that it also exposes a web server for you to integrate the LLM into your application. As an example, here&#39;s how you would curl your local LLM:</p>

<p><code>
curl http://localhost:11434/api/chat -d &#39;{
    &quot;model&quot;: &quot;llama3&quot;,      
    &quot;messages&quot;: [{ &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Are you a robot?&quot; }],
    &quot;stream&quot;: false
}&#39;
{&quot;model&quot;:&quot;llama3&quot;,&quot;created_at&quot;:&quot;2024-06-17T11:19:23.510588Z&quot;,&quot;message&quot;:{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I am not a human, but I&#39;m also not a traditional robot. I&#39;m an artificial intelligence language model designed to simulate conversation and answer questions to the best of my ability. My \&quot;brain\&quot; is a complex algorithm that processes natural language inputs and generates responses based on patterns and associations learned from large datasets.\n\nWhile I don&#39;t have a physical body or consciousness like humans do, I&#39;m designed to interact with humans in a way that feels natural and conversational. I can understand and respond to questions, make suggestions, and even tell jokes (though my humor may be a bit... algorithmic).\n\nSo, while I&#39;m not a human or a traditional robot, I exist at the intersection of technology and language, designed to assist and communicate with humans in a helpful way!&quot;},&quot;done_reason&quot;:&quot;stop&quot;,&quot;done&quot;:true,&quot;total_duration&quot;:12565842250,&quot;load_duration&quot;:7059262291,&quot;prompt_eval_count&quot;:15,&quot;prompt_eval_duration&quot;:331275000,&quot;eval_count&quot;:156,&quot;eval_duration&quot;:5172858000}
</code></p>

<p>If your local machine is not beefy enough and you want to try out a large LLM on a rented server (AWS has <code>g5.2xlarge</code>, which gave me good results for <code>mixtral 8x7b</code>), you also have to set <code>OLLAMA_HOST=0.0.0.0</code> in your environment variables to be able to reach the remote server. <strong>This exposes the LLM to the public internet, so be careful when chosing your deployment strategy.</strong></p>

<p>And there you go! You just deployed your very own LLM. Pretty cool, huh?</p>]]>
            </description>
        </item>
        <item>
            <title>
                Going from self hosted to managed software
            </title>
            <guid>
                https://garrit.xyz/posts/2024-05-24-going-from-self-hosted-to-managed-software
            </guid>
            <link>
                https://garrit.xyz/posts/2024-05-24-going-from-self-hosted-to-managed-software?utm_source=rss
            </link>
            <pubDate>
                Fri, 24 May 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Some time ago I was heavily into <a href="https://garrit.xyz/posts/2022-09-26-self-hosted-software-im-thankful-for">self hosting my own software</a>. Over time though, it became apparent that maintaining these services is a huge burden. I either abandoned most of the services or found a replacement that suits my needs and saves me time that&#39;s better spent on other things in life.</p>

<p>Today, I finally pulled the plug on <a href="https://miniflux.app/">Miniflux</a>, the last service I used to self host (not counting House Assistant on a Pi, which I use to automate some stuff at home). The Hetzner server it ran on cost me ~4â‚¬ a month. The maintainer of Miniflux offers a managed hosting solution for 15$ a year, so to save money and time, and to support the project, I decided to switch from self-hosted to managed.</p>

<h2>Will I ever self host again?</h2>

<p>I really don&#39;t know. Some services (Miniflux included) required very little maintenance to keep running, so I could see myself spinning up a server again if I really wanted to run some software that doesn&#39;t have managed hosting. For now though, I&#39;m planning on using managed services wherever I can. Nevertheless I&#39;m proud of the things I learned during my time of self hosting my software. I think it gave me a huge boost both in terms of know how and my career, and I&#39;d encourage everyone to dip a toe into self hosting.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Migrating Homeassistant from SD to SSD
            </title>
            <guid>
                https://garrit.xyz/posts/2023-04-27-migrating-homeassistant-from-sd-to-ssd
            </guid>
            <link>
                https://garrit.xyz/posts/2023-04-27-migrating-homeassistant-from-sd-to-ssd?utm_source=rss
            </link>
            <pubDate>
                Thu, 27 Apr 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I finally got frustrated with the performance of my Raspberry Pi 4 running Homeassistant on a SD card, so I went ahead and got an SSD.</p>

<p>The migration was <strong>very</strong> easy:</p>

<ol><li>Create and download a full backup through the UI</li><li>Flash Homeassistant onto the SSD</li><li>Remove the SD card and plug the SSD into a USB 3.0 port of the Pi</li><li>Boot</li><li>Go through the onboarding procedure</li><li>Restore Backup</li><li>Profit</li></ol>

<p>It worked like a charm! The speed has improved A LOT, and everything was set up as it should be. </p>

<p>...Until we turned on the lights in the livingroom. My ZigBee-dongle, plugged into another USB port, wasn&#39;t able to communicate with the devices on the network.</p>

<p>After some digging around, I came across several threads stating that an SSD over USB 3.0 apparently creates a lot of interference to surrounding hardware, including my ZigBee dongle. The fix was simple: either get an extension port for the dongle, or plug the SSD into a USB 2.0 port of the Pi. Since I didn&#39;t have an extension cord to get the dongle far away enough from the SSD, I went with the latter option for now. And that fixed it! The performance was much worse, but still better than the SD I used before. My next step will be to grab an extension cord from my parents. I&#39;m sure they won&#39;t mind.</p>

<p>I hope this helps!</p>

<hr/>

<p>This is post 066 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Self-hosted software I'm thankful for
            </title>
            <guid>
                https://garrit.xyz/posts/2022-09-26-self-hosted-software-im-thankful-for
            </guid>
            <link>
                https://garrit.xyz/posts/2022-09-26-self-hosted-software-im-thankful-for?utm_source=rss
            </link>
            <pubDate>
                Mon, 26 Sep 2022 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Self-hosting software is not just rainbows and sunshine. I used to self-host a lot of my tools, but after some time the burden of maintaining those tools made me switch to hosted alternatives.</p>

<p>However, there are a few projects that I stuck with over the years, and which I think deserve a deep appreciation.</p>

<h2>Miniflux</h2>

<p><a href="https://miniflux.app/">Miniflux</a> is a very minimal, self-hostable RSS reader. It&#39;s been rock-solid since they day I started using it. The data for the application entirely lives In a Postgres database, which makes migrating the application to new infrastructure setups an absolute breeze. I&#39;ve been meaning to support the author for quite some time now, but the cost of maintaining an instance yourself is basically zero, so I&#39;ve yet to find the time to switch to their paid hosted instance.</p>

<h2>Plausible Analytics</h2>

<p><a href="https://plausible.io/">Plausible</a> is another tool that just keeps on running. I haven&#39;t had any issues with it whatsoever, and I can&#39;t remember the last time I had to do a manual intervention. Just like Miniflux, there&#39;s a paid instance, which supports the author, and just like Miniflux, the software is so good that I haven&#39;t had a reason to switch to it yet. Oh, the irony.</p>

<h2>BirdsiteLIVE</h2>

<p>While my instance of <a href="https://birdsite.slashdev.space/">BirdsiteLIVE</a> is currently in a bad shape, this is not at all the fault of the software. There are limitations to the amount of Twitter API requests you can make, and I did a poor job managing the users on that instance. It&#39;s currently very overloaded and just very few tweets make it through. I will have to set aside some time to fix this, but the software itself has been rock solid since the day I started using it.</p>

<h2>Synapse (Matrix)</h2>

<p>I was hesitant to mention <a href="https://matrix.org/">Matrix</a> on this list. I had my ups and downs with Synapse (their Python implementation of a Matrix server), but the fact that my instance is still running after multiple infrastructure transitions and even a migration from SQLite to Postgres says something about the quality of the software. I have a feeling that Synapse is fairly resource-hungry, but if you feed it with enough RAM and disk, it will keep running indefinitely.</p>

<h2>Homeassistant</h2>

<p>You can throw <a href="https://www.home-assistant.io/">Homeassistant</a> on a Raspberry Pi and everything works out of the gate. I even migrated my instance from a RPi 3 to a RPi 4 via their backup and restore functionality. It&#39;s absolutely flawless.</p>

<h2>Dead projects</h2>

<p>I think it&#39;s fair to also mention the software that I no longer self-host.</p>

<h3>E-Mail</h3>

<p>Just don&#39;t roll your own email.</p>

<h3>Mastodon</h3>

<p>Too power hungry for my taste. No easy way to host inside docker, which made it a pain to keep running. I&#39;m very happy with <a href="https://fosstodon.org/">Fosstodon</a>, and don&#39;t see a reason to switch to a self-hosted instance any time soon.</p>

<h3>FreshRSS</h3>

<p>I tried replacing Miniflux once, but failed. Nothing beats Miniflux.</p>

<h3>Prometheus + Grafana</h3>

<p>Monitoring <strong><em>inside</em></strong> your infra works until the infra goes down, at which point you&#39;re essentially driving blindfolded. I switched to Grafana Cloud, which includes a very generous free tier.</p>

<p>This is post 038 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Postgres Docker Container Migration Cheat Sheet
            </title>
            <guid>
                https://garrit.xyz/posts/2022-05-31-database-server-migration-cheat-sheet
            </guid>
            <link>
                https://garrit.xyz/posts/2022-05-31-database-server-migration-cheat-sheet?utm_source=rss
            </link>
            <pubDate>
                Tue, 31 May 2022 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I just finished migrating a postgres database to a new host. To remember how to
do it next time, I&#39;m writing down the commands I used here.</p>

<p>I usually just shut down the database and then copy the local directory where
the volume was mounted onto the new host. This time though, I seemed to be
getting some I/O errors, so I had to do it the &quot;right&quot; way.</p>

<p>To be fair, this note is based on
<a href="https://www.netguru.com/blog/how-to-dump-and-restore-postgresql-database">this</a>
guide. I modified it to fit my workflow with docker.</p>

<h2>Creating a dump</h2>

<p>Log into the old host:</p>

<p><code>
ssh &lt;user&gt;@host
</code></p>

<p>Connect to the postgres-container:</p>

<p><code>
docker exec -ti myservice_db_1 /bin/bash
</code></p>

<p>Create a dump. You can name your dump as you wish - I&#39;m using dates to
distinguish multiple dumps:</p>

<p><code>
pg_dump -U db_user db_name &gt; db_name_20220531.sql
</code></p>

<p>Copy the dump to the host machine:</p>

<p><code>
docker cp myservice_db_1:/db_name_20220531.sql ~/
</code></p>

<h2>Moving the dump to the new host</h2>

<p>The easiest way to get the dump off of the old server and onto the new one is to
use your local machine as a middleman.</p>

<p>First, download the dump to your machine:</p>

<p><code>
scp &lt;user&gt;@&lt;host&gt;:~/db_name_20220531.sql .
</code></p>

<p>Then, do the same thing but reversed, with the new host:</p>

<p><code>
scp ./db_name_20220531.sql &lt;user&gt;@&lt;host&gt;:~/
</code></p>

<h2>Restoring the dump</h2>

<p>First, connect to the new host:</p>

<p><code>
ssh &lt;user&gt;@&lt;host&gt;
</code></p>

<p>Assuming the docker service is already running on the new host, attach to the
db-container, just like above:</p>

<p><code>
docker exec -ti myservice_db_1 /bin/bash
</code></p>

<p>This time, we have to do some fiddling on the database, so attach a session to
postgres using their cli:</p>

<p><code>
psql -U my_user
</code></p>

<p>Before &quot;resetting&quot; the existing DB to apply the dump, we have to connect to
another database. The <code>postgres</code> DB is always there, so you can use that.</p>

<p><code>
\c postgres
</code></p>

<p>Now, we drop the existing DB and re-add it:</p>

<p><code>sql
drop database database_name;
create database database_name with owner your_user_name;
</code></p>

<p>And now, the moment you&#39;ve been waiting for! Leave the psql-session and apply
the dump:</p>

<p><code>
psql -U db_user db_name &lt; db_name_20220531.sql
</code></p>

<p>That&#39;s all! You now have the exact copy of production database available on your
machine.</p>

<p>This is post 032 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Fixing Traefik Proxy Issues
            </title>
            <guid>
                https://garrit.xyz/posts/2022-03-18-fix-traefik-proxy-issues
            </guid>
            <link>
                https://garrit.xyz/posts/2022-03-18-fix-traefik-proxy-issues?utm_source=rss
            </link>
            <pubDate>
                Fri, 18 Mar 2022 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>After changing my proxy from NGINX to Traefik, I noticed that some of my
services started misbehaving.</p>

<p>In particular, my instance of
<a href="https://github.com/NicolasConstant/BirdsiteLive">BirdsiteLive</a>
(<a href="https://birdsite.slashdev.space">birdsite.slashdev.space</a>) had issues
forwarding tweets to the
<a href="https://garrit.xyz/posts/2021-01-18-reasons-the-fediverse-is-better">Fediverse</a>.</p>

<p>The only difference between my old NGINX and my Traefik config were the headers.
I didn&#39;t think that that&#39;s what&#39;s causing the issue, but after digging around a
bit I figured out what&#39;s wrong. I still can&#39;t wrap my head around it entirely,
but it has something to do with forwarding external <code>https</code> requests to internal
<code>http</code> services, since the <code>x-forwarded-</code> headers where missing in the forwarded
requests.</p>

<p>In the world of NGINX, we can instruct the proxy to forward <em>all</em> headers using
this directive:</p>

<p><code>conf
proxy_pass_request_headers      on;
</code></p>

<p>which takes care of the issue. In Traefik, it&#39;s a bit more convoluted. Traefik
can use a combination of &quot;Entrypoints&quot; and middleware to route traffic around.
In my setup, I use a <code>webSecure</code> entrypoint listening for SSL/TLS traffic, and a
<code>web</code> entrypoint that just redirects to <code>webSecure</code>:</p>

<p><code></code>`yaml
entryPoints:
  web:
    address: :80
    http:
      redirections:
        entryPoint:
          to: &quot;websecure&quot;
          scheme: &quot;https&quot;</p>

<p>  websecure:
    address: :443
<code></code>`</p>

<p>Apparently, some services send requests to the <code>web</code> entrypoint, and the
<code>x-forwarded-for</code> headers are dropped. To prevent this, you can set the
<code>proxyProtocol</code> and <code>forwardedHeaders</code> in the <code>web</code> entrypoint to <code>insecure</code>,
like so:</p>

<p><code></code>`yaml
entryPoints:
  web:
    address: :80
    proxyProtocol:
      insecure: true
    forwardedHeaders:
      insecure: true
    # ...</p>

<h1>...</h1>

<p><code></code>`</p>

<p>I&#39;m sure there&#39;s a reason why this is marked as <code>insecure</code>, but it behaves just
like the NGINX counterpart, so I didn&#39;t bother digging deeper into the matter.
Maybe one day I&#39;ll come back to properly fix this.</p>

<p>If you want to read more, check out
<a href="https://medium.com/@_jonas/traefik-kubernetes-ingress-and-x-forwarded-headers-82194d319b0e">this</a>
article on Medium. It explains the issue in more detail.</p>

<hr/>

<p>This is post 025 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                BTRFS on Alpine Linux
            </title>
            <guid>
                https://garrit.xyz/posts/2021-12-31-btrfs-on-alpine
            </guid>
            <link>
                https://garrit.xyz/posts/2021-12-31-btrfs-on-alpine?utm_source=rss
            </link>
            <pubDate>
                Fri, 31 Dec 2021 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I&#39;m currently in the midst of migrating some of my infrastructure from the cloud
to &quot;on prem&quot;, aka a local server, aka my old PC. I wanted to try alpine linux as
the host OS to see how it behaves as a lightweight server distro.</p>

<p>So far it stands up quite nicely, it has everything you&#39;d expect from a
linux-based operating system. The only problem I encountered was getting BTRFS
to work out of the box. Here are some things you should know when using BTRFS on
Alpine linux.</p>

<h3>Installing BTRFS</h3>

<p>Installing BTRFS is relatively straight forward. Simply install the package and
tell Alpine to load the module on startup:</p>

<p><code>
apk add btrfs-progs
echo btrfs &gt;&gt; /etc/modules
</code></p>

<p>To load the module right away, you can use the following command:</p>

<p><code>
modprobe btrfs
</code></p>

<h3>Mounting a volume</h3>

<p>If you try mounting a btrfs volume via your fstab, you will get an error. This
is because BTRFS does not know about the drives yet when the filesystems are
mounted. To work around this, you can create an OpenRC service that runs a
<code>btrfs scan</code> to detect the drives. To do so, create a service under
<code>/etc/init.d/btrfs-scan</code> with the following content:</p>

<p><code></code>`sh</p>

<h1>!/sbin/openrc-run</h1>

<p>name=&quot;btrfs-scan&quot;</p>

<p>depend() {
  before localmount
}</p>

<p>start() {
  /sbin/btrfs device scan
}
<code></code>`</p>

<p>Make the service executable and register it:</p>

<p><code>
chmod +x /etc/init.d/btrfs-scan
rc-update add btrfs-scan boot
</code></p>

<p>Now, you should be able to add the volume to your <code>/etc/fstab</code>:</p>

<p><code>
UUID=abcdef-0055-4958-990f-1413ed1186ec  /var/data  btrfs   defaults,nofail,subvol=@  0  0
</code></p>

<p>After a reboot, you should be able to see the drive mounted at <code>/var/data</code>.</p>

<h3>Resources</h3>

<ul><li><a href="https://nparsons.uk/blog/using-btrfs-on-alpine-linux">Nathan Parsons - &quot;Using BTRFS on Alpine Linux&quot;</a></li><li><a href="https://gitlab-test.alpinelinux.org/alpine/aports/-/issues/9539">A bug report about this problem</a></li></ul>

<p>This is post 023 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Finally fixing that annoying Cron gotcha
            </title>
            <guid>
                https://garrit.xyz/posts/2021-09-13-fixing-an-annoying-cron-gotcha
            </guid>
            <link>
                https://garrit.xyz/posts/2021-09-13-fixing-an-annoying-cron-gotcha?utm_source=rss
            </link>
            <pubDate>
                Mon, 13 Sep 2021 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>A while ago I went through my server and reworked my <a href="/posts/2021-02-07-storage-setup">storage
setup</a>. As discribed in that blog post, I set
up daily backups to <a href="https://www.backblaze.com/cloud-storage">Backblaze
B2</a> using their amazing CLI
through a cron script. A day went by and I noticed that the
<a href="/posts/2021-05-15-healthchecks-io-with-docker">healthcheck</a> didn&#39;t pass.
Unfortunately I didn&#39;t have time to fix this problem immediately, so instead I
executed the command by hand every couple of days. One could argue that this in
total took way more time than the actual fix, but hey, I was lazy. In the end,
I finally dedicated some time to fix this annoying issue.</p>

<p>It turns out that a command executed by cron doesn&#39;t run through sh or bash,
but in a minimal environment without your usual environment-variables. As a
result, my <code>b2</code> command (and many other commands for that matter) won&#39;t run as
expected, if at all. A quick fix is to run your command through bash or sh
explicitly:</p>

<p><code>sh
sh -c &quot;mycommand&quot;
</code></p>

<p>Alternatively, if you want all your entries to use sh or bash, you can set the
<code>SHELL</code> variable at the very beginning of your crontab:</p>

<p><code></code>`sh
SHELL=/bin/bash</p>

<p>15 1 <em> </em> * some_command
<code></code>`</p>

<p><a href="https://askubuntu.com/a/23438">Here</a> is an answer that goes into more detail
about this. Have a great day!</p>

<p>This is post 019 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Docker healthchecks using healthchecks.io
            </title>
            <guid>
                https://garrit.xyz/posts/2021-05-15-healthchecks-io-with-docker
            </guid>
            <link>
                https://garrit.xyz/posts/2021-05-15-healthchecks-io-with-docker?utm_source=rss
            </link>
            <pubDate>
                Sat, 15 May 2021 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I&#39;m currently in the midst of improving the monitoring of my infrastructure. I
make heavy use of docker and docker-compose for my hosting, so it&#39;s vital to add
monitoring for most of the containers.</p>

<p>I&#39;m hosting my own instance of <a href="https://healthchecks.io/">healthchecks.io</a>.
Their solution to monitoring involves <strong>you</strong> having to ping <strong>them</strong>, instead
of the other way around. This let&#39;s you add healthchecks to virtually anything
that can ping a http-endpoint.</p>

<p>docker-compose let&#39;s you define healthchecks to your config that, when
completing sucessfully, mark the container as &quot;healthy&quot;. The process of adding
such a healthcheck is simple. First, create a new check in your healthchecks.io
account and set the ping interval to 1 minute, or a value you prefer. Then, add
this snippet to your docker-compose file:</p>

<p><code>yaml
app:
  image: nextcloud
  ports:
    - 127.0.0.1:8080:80
  healthcheck:
    test:
      [
        &quot;CMD&quot;,
        &quot;curl&quot;,
        &quot;-f&quot;,
        &quot;https://app-endpoint.tld&quot;,
        &quot;&amp;&amp;&quot;,
        &quot;curl&quot;,
        &quot;-fsS&quot;,
        &quot;-m&quot;,
        &quot;10&quot;,
        &quot;--retry&quot;,
        &quot;5&quot;,
        &quot;-o&quot;,
        &quot;/dev/null&quot;,
        &quot;https://healthchecks.io/ping/&lt;UUID&gt;&quot;,
      ]
    interval: 60s
    timeout: 10s
    retries: 6
</code></p>

<p>Change the first url to the url of your app. The second URL is the endpoint of
your healthchecks.io instance. You can obtain it from the check you configured
earlier.</p>

<p>This configuration will try to ping your application and, if successful, notify
the healthcheck that the application is healthy. If the app is not reachable or
the container is down, the latter request will not be executed and your service
is marked as &quot;down&quot;.</p>

<p>In addition to the healthchecks of my docker containers, I also added basic
healthchecks to my servers cronfiles and its backup-commands.</p>

<p>Do you have any suggestions regarding this topic? Feel free to reach out to me
via Matrix or email!</p>

<p>This is post 017 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
    </channel>
</rss>